{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本分类实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             review\n",
       "0      1  距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...\n",
       "1      1                       商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!\n",
       "2      1         早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。\n",
       "3      1  宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...\n",
       "4      1               CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./ChnSentiCorp_htl_all.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7766, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7765, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 创建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(\"./ChnSentiCorp_htl_all.csv\")\n",
    "        self.data = self.data.dropna()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index][\"review\"], self.data.iloc[index][\"label\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较为简单.', 1)\n",
      "('商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!', 1)\n",
      "('早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。', 1)\n",
      "('宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小，但加上低价位因素，还是无超所值的；环境不错，就在小胡同内，安静整洁，暖气好足-_-||。。。呵还有一大优势就是从宾馆出发，步行不到十分钟就可以到梅兰芳故居等等，京味小胡同，北海距离好近呢。总之，不错。推荐给节约消费的自助游朋友~比较划算，附近特色小吃很多~', 1)\n",
      "('CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风', 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset()\n",
    "for i in range(5):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6988, 777)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "total_len = dataset.__len__()\n",
    "trainset_len = (int) (total_len * 0.9)\n",
    "validset_len = total_len - trainset_len\n",
    "trainset, validset = random_split(dataset, lengths=[trainset_len, validset_len])\n",
    "len(trainset), len(validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('服务很好，房间也很明亮，性价比还算不错。', 1)\n",
      "('酒店位置、房间都很不错，价格也比较合适，推荐大家去住', 1)\n",
      "('从永州回到长沙，由于是学生返回的高峰期，酒店需要信用卡担保，但是由于我丢了钱包还没有补办好，因此只有到酒店前台进行确认有无房间。到了前台服务人员告知有房间，通过携程预定后，但是前台小姐的脸色又非常不好看了，直接告诉我，办理办理一张他们的酒店卡，比携程的方便（我靠，我又不是傻子），这个时候有一个客人来了，小姐依然用同样的话告诉他，这个客户同意了，我就在旁边看，结果和我预定是相同的房间，的确便宜20元，但是根本没有给这个客户一张会员卡，然后这个服务元很傲气地斜眼看了我，但是那个郁闷哦！又在大厅等待了20分钟，多次催促小姐去拿传真，根本不理睬你，最后我发飙要向长沙旅游局投诉，这才给我办理手续（该前台服务员姓刘）。由于上次入住没有了经验，我这次要求楼层要高，而且不能够窗户对准51大道，避免吵闹，给我了1820号房间，进去感觉房间比上次的8901房间好一些，但是窗帘关闭不严的毛病依然存在。第二天从客户那里回来，已经是晚上8点多了，打开房间一看，结果发现依然没有打扫，呵呵，我感觉这家酒店对携程的客户估计当作二等房客来对待的，希望携程和这个酒店好好沟通一下。', 0)\n",
      "('酒店坐落的位置很好,闲暇在湖边散步很是惬意.酒店的前厅部人员很热情,去了酒店几次，感觉都不错。', 1)\n",
      "('酒店服务还不错,在宜宾已经很好了.但是携程的价格一点都没有,豪标B在前台打折价265,携程263,希望以后携程要大大改进价格偏偏高的问题,才能有吸引了!!!', 1)\n",
      "('酒店设施老,服务态度差,这么热的天不开空调,动不动就说你们是优惠房价,不享受空调是应该的,其实整栋楼是因为入住率低才不舍得开空调的,当然泳池也不会开放的.根本没有达到4星级的服务标准,更别说服务意识了.提醒大家千万别看以前的点评,估计是他们自己人写的.因为360的饭费不包括早餐,前台竟然说如果我们付360的现金就可以早餐优惠10元,试想这是正规的酒店么?房间发票开好再想起没有查房,谁还高兴等他们查房,自然一走了之了,早知道,怎么也带点东西走呢.宾馆反馈2008年7月28日：尊敬的客人，首先我们感谢您选择入住本酒店并提出宝贵意见。对于你在住店期间的不愉快感受，我们表示诚挚的歉意。酒店对您的感受非常重视，已召开了部门的专题会议同时我们也会加强对员工的培训工作，更好的提高服务质量。希望您能再次光临本酒店，如果您在店期间遇到任何问题，请与相关部门联系，我们会圆满的为您解决，谢谢。关于您提到的饭店内部自行点评，本酒店将做特别申明：酒店无法登陆携程网的点评平台，只有客人通过携程预定并成功入住才能进入该平台，所以我们是无法自行点评的。对于您在店期间的不愉快经历，我们再次向您表示真诚的歉意。', 0)\n",
      "('08.4.28-30号住了两天，感觉该酒店物超所值。干净宽敞，安静，床很舒服。洗澡水很热很大。值得再住。早餐很一般，但针对这个价格还可以了。', 1)\n",
      "('总体感觉还不错，就是从机场到酒店不是很方便，需要坐机场大巴，下车之后还打的（走的话还是有点距离的）。就这个价位而言，房间还算可以。就是商务中心的工作人员下班太早了，如果可以在晚上也接受我们的订票需要，那就会方便很多。宾馆反馈2008年4月15日：酒店反馈2008年4月8日：感谢阁下的宝贵意见，我们将考虑延长商务中心的服务时间，为客人提供更多的便利。', 1)\n",
      "('酒店就在海水浴场旁边，出门到接触到海水两分钟，如果要和海水亲近的朋友，极力推荐。这样游泳换衣服啥的就很方便了。山景房是朝马路的一边，便宜点，海景房是可以看到海的。房间很大。40个平方左右。条件不错。没有叫服务员弄一些端吃的上来之类的事情。反正登记和结账的时候态度还不错。我要求不高，可以看电视上网就好。一楼还有台球桌。本来说不要钱可以玩得，还是要了我们30块，出来玩也不想弄不开心，给他们了。到市区就打车好了，威海的taxi很便宜，从这里到市区最多17块钱。旁边的沙滩真不错，免费，金黄色的沙滩，碧绿的海水，很好。有一点有点遗憾，就是第一天去的时候洗澡的热水有点问题，黄黄的，不知道是锈迹还是什么。不过第二天就好了。补充点评2007年10月6日：看了下面朋友们的推荐，补充一下，确实离4星级有差距，我也没有看到前台那有4星的评定级别，只是从他们的自我介绍中说是按照4星级配置。服务员素质一般，没有那种很主动和热情的态度。另外还有一件事情，不让把浴巾等带到浴场，去游泳的朋友还是得自己准备浴巾。我准备很不充分，打赤脚去游泳，经过大厅的时候有个穿制服的服务员模样的人跟我说不让打赤脚进大厅，我说你们又不让把房间的鞋子(其实也就是一次次性的鞋拖)穿出去，也不给配备双沙滩拖鞋，我出来住酒店总不能自己带双拖鞋来吧，那人才闭嘴。所以建议酒店放两双沙滩拖鞋在房间，花不了几个钱但是非常实用。鉴于我对酒店总体要求不高，总的评价偏高，希望对别的朋友有用！', 1)\n",
      "('住的行政大床房,实在是喜欢西郊里的环境,院子里的黑天鹅,丹顶鹤,还有西郊的小野猫,繁华上海中的安逸休息之地,以后去上海都住这里.', 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(trainset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 创建DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./rbt3\")\n",
    "\n",
    "def collate_func(batch):\n",
    "    texts, labels = [], []\n",
    "    for item in batch:\n",
    "        texts.append(item[0])\n",
    "        labels.append(item[1])\n",
    "    inputs = tokenizer(texts, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    inputs[\"labels\"] = torch.tensor(labels)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# trainloader = DataLoader(trainset, batch_size=32, shuffle = True)\n",
    "# validloader = DataLoader(validset, batch_size=64, shuffle = False)\n",
    "# 此时数据还是文字，而label是tensor\n",
    "# 需要collate function处理数据为tensor\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=collate_func)\n",
    "validloader = DataLoader(validset, batch_size=64, shuffle=False, collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2791, 7313,  ..., 4510, 6228,  102],\n",
       "        [ 101, 3297, 4289,  ..., 1220,  711,  102],\n",
       "        [ 101, 1963, 3362,  ..., 1391, 3193,  102],\n",
       "        ...,\n",
       "        [ 101, 1765, 4157,  ...,    0,    0,    0],\n",
       "        [ 101, 2769, 1343,  ...,    0,    0,    0],\n",
       "        [ 101, 2769, 1762,  ..., 1862,  679,  102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看trainloader\n",
    "# next(enumerate(trainloader)) # 返回一个tuple[batch number, [data, label]]\n",
    "next(enumerate(trainloader))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 创建模型及优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./rbt3 were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./rbt3\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in validloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            output = model(**batch)\n",
    "            pred = torch.argmax(output.logits, dim=-1)\n",
    "            acc_num += (pred.long() == batch[\"labels\"].long()).float().sum()\n",
    "    return acc_num / len(validset)\n",
    "\n",
    "def train(epoch=3, log_step=100):\n",
    "    global_step = 0\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for batch in trainloader:\n",
    "            if torch.cuda.is_available():\n",
    "                batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "            if global_step % log_step == 0:\n",
    "                print(f\"ep: {ep}, global_step: {global_step}, loss: {output.loss.item()}\")\n",
    "            global_step += 1\n",
    "        acc = evaluate()\n",
    "        print(f\"ep: {ep}, acc: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, global_step: 0, loss: 0.9110406041145325\n",
      "ep: 0, global_step: 100, loss: 0.20251959562301636\n",
      "ep: 0, global_step: 200, loss: 0.3933698236942291\n",
      "ep: 0, acc: 0.8931788802146912\n",
      "ep: 1, global_step: 300, loss: 0.5275416374206543\n",
      "ep: 1, global_step: 400, loss: 0.26682645082473755\n",
      "ep: 1, acc: 0.9086229205131531\n",
      "ep: 2, global_step: 500, loss: 0.16997507214546204\n",
      "ep: 2, global_step: 600, loss: 0.28405457735061646\n",
      "ep: 2, acc: 0.8944659233093262\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：我觉得这家酒店不错，饭很好吃！\n",
      "模型预测结果:好评！\n"
     ]
    }
   ],
   "source": [
    "sen = \"我觉得这家酒店不错，饭很好吃！\"\n",
    "id2_label = {0: \"差评！\", 1: \"好评！\"}\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(sen, return_tensors=\"pt\")\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    pred = torch.argmax(logits, dim = -1)\n",
    "    print(f\"输入：{sen}\\n模型预测结果:{id2_label.get(pred.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model.config.id2label = id2_label\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '好评！', 'score': 0.9969170093536377}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textcls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
